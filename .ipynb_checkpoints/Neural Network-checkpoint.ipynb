{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "#Neural network class def\n",
    "class neuralNetwork:\n",
    "\n",
    "    #initialize network\n",
    "    def __init__(self, inputNodes, hiddenNodes, outputNodes, learningRate):\n",
    "        self.inodes = inputNodes\n",
    "        self.hnodes = hiddenNodes\n",
    "        self.onodes = outputNodes\n",
    "        self.lr = learningRate\n",
    "        #Weights matricies created with random numbes\n",
    "        #Chosen from a normal distribution with center 0 and std dev (1/sqrt(n))\n",
    "        #Where n is number of nodes inputting into that neuron\n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "        #Activation function is sigmoid function\n",
    "        self.activ_func = sigmoid\n",
    "    #Train network\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        final_outputs, hidden_outputs = self.query(inputs_list)\n",
    "        output_errors = targets - final_outputs\n",
    "        #Propogate errors backwards\n",
    "        hidden_errors = np.dot(self.who.T,output_errors)\n",
    "        #Update weights given errors\n",
    "        self.who+=self.lr*np.dot((output_errors*final_outputs*(1-final_outputs)), np.transpose(hidden_outputs))\n",
    "        self.wih+=self.lr*np.dot((hidden_errors*hidden_outputs*(1-hidden_outputs)), np.transpose(inputs))\n",
    "    #Query network\n",
    "    def query(self, inputs_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.activ_func(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.activ_func(final_inputs)\n",
    "        \n",
    "        return final_outputs, hidden_outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create the network\n",
    "n = neuralNetwork(784, 100, 10, 0.2)\n",
    "\n",
    "#Read the training data\n",
    "data_file = open(\"MNIST data/mnist_train.csv\", 'r')\n",
    "\n",
    "epochs = 7 #Go through the data multiple times\n",
    "#Train the network\n",
    "for e in range(epochs):\n",
    "    while True:\n",
    "        record = data_file.readline()\n",
    "        if record=='':\n",
    "            break\n",
    "        all_values = record.split(',')\n",
    "        #Scale inputs to be in range [0.01,1]\n",
    "        scaled_inputs=np.asfarray(all_values[1:])/255.0*0.99+0.01\n",
    "        #We want 10 output nodes, for 0-9\n",
    "        onodes=10\n",
    "        #Have all the output nodes be 0.01, except for the correct value, which is 0.99\n",
    "        targets = np.zeros(onodes)+0.01\n",
    "        targets[int(all_values[0])]=0.99\n",
    "        n.train(scaled_inputs, targets)\n",
    "    data_file.seek(0)\n",
    "\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read the test data\n",
    "test_file = open(\"MNIST data/mnist_test.csv\", 'r')\n",
    "\n",
    "#See how well the network performs\n",
    "scorecard=[]\n",
    "\n",
    "#Test the network\n",
    "while True:\n",
    "    record = test_file.readline()\n",
    "    if record=='':\n",
    "        break\n",
    "    all_values=record.split(\",\")\n",
    "    correct_label = int(all_values[0])\n",
    "    #Scale the inputs\n",
    "    inputs = np.asfarray(all_values[1:])/255*0.99+0.01\n",
    "    outputs, _ = n.query(inputs)\n",
    "    #Find the computers response\n",
    "    label = np.argmax(outputs)\n",
    "    #Compare correct answer with network answer\n",
    "    score = 1 if label==correct_label else 0\n",
    "    scorecard.append(score)\n",
    "    #print(\"{}:{}\".format(correct_label, label))\n",
    "\n",
    "test_file.close() #Close file\n",
    "\n",
    "score_array = np.asarray(scorecard)\n",
    "print(scorecard)\n",
    "#Find the percentage of correct answers\n",
    "print(\"Score is \",score_array.sum()/score_array.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='MNIST data/mnist_train.csv' mode='r' encoding='cp1252'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
